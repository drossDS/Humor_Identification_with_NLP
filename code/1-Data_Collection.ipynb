{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec24a5a-3cd1-488d-a458-a3d27a5f4476",
   "metadata": {},
   "source": [
    "# 1 - Project 3 Data Collection\n",
    "This is the first of a series of notebooks for this project.\n",
    "\n",
    "Note that subsquent project notebooks will refer to this notebook.  As running this notebook will provide data for a fixed point in time, and could potentially over-write data collected previously, this will be treated as a stand-alone notebook.  Timestamps will be printed to a csv so that this code can be modified to duplicate the run shown in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fb4f2-ee6e-41d0-9349-ba7ff2d3de61",
   "metadata": {},
   "source": [
    "# Initial Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa8e9b8-51b3-43c9-ad24-b9b3dfd1e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Sourece to get current Unix Timestamp for the pushshift API:\n",
    "#  https://stackoverflow.com/questions/16755394/what-is-the-easiest-way-to-get-current-gmt-time-in-unix-timestamp-format\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e1729-bf37-4f2c-ac49-1a8dbe691269",
   "metadata": {},
   "source": [
    "# Define Data Gathering Function\n",
    "This function accomplishes the following:\n",
    "* Connects to the internet\n",
    "* Retrieves data with the pushshift API\n",
    "* Gathers data in approximately 1000 submission increments known as 'trials'\n",
    "* Prints the website status code after each successful trial\n",
    "* Creates timestamps for when the data are pulled for each trial and the time beforewhich data are collected through the API (the before parameter)\n",
    "    * The pushshift API has a parameter 'before' which is redifined to be the unix timestamp of the oldest submission in the previous trail.  As pushshift will by defualt pull the current most recent submissions, it will only collect about 1000 submissions at a time.  To get more than 100 submissions, the 'before' parameter must be set at each trial to collecte submissions prior to the oldest previously gathered submission\n",
    "* Saves these timestamps to a text file so that they can be referenced if the data need to be replicated\n",
    "    * The text file is named with the 'name' parameter and the unix timestamp for which the data were pulled to automatically differential this data from any prior or subsequent calls of this function to the same subreddit\n",
    "* Saves a dataframe which concatenates all data from the previous trials\n",
    "    * The text file is named with the 'name' parameter and the unix timestamp for which the data were pulled to automatically differential this data from any prior or subsequent calls of this function to the same subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a1b618-00d2-4736-9fda-f921883d8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_getter(subreddit, trials, name):\n",
    "#=====  INITIAL LOCAL VARIABLES  =================================================================================\n",
    "    \n",
    "    # Establish base url:\n",
    "    url_fnc = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    \n",
    "    # Establish initial parameters for most current subreddit pull:\n",
    "    params_getter = {\n",
    "    'subreddit': subreddit,\n",
    "    'size': 1000,\n",
    "    }\n",
    "    \n",
    "    # Create an empty dataframe to which we can concatenate each run\n",
    "    master_df = pd.DataFrame()\n",
    "    \n",
    "    # Create the first instance of the timestamp list, and establish current time\n",
    "    right_now = round(time.time())\n",
    "    pull_times = [right_now]\n",
    "    \n",
    "#=====  Gathering the data from reddit/pushshift // Create DataFrame // Concatenate to Master  ===================\n",
    "    \n",
    "    # Get the data:\n",
    "    res_fnc = requests.get(url_fnc, params_getter)\n",
    "    print(res_fnc.status_code) # for debugging, prints the website status code to show function progress\n",
    "    \n",
    "    # Make dataframe:\n",
    "    df = res_fnc.json() # Dump dat to a json\n",
    "    df = pd.DataFrame(df['data']) # Pull the 'data' dictionary out of the json\n",
    "    \n",
    "    # Concatenate to master\n",
    "    master_df = pd.concat([master_df, df])\n",
    "\n",
    "#=====  Iterate the above steps over remaining trials  ===========================================================\n",
    "    for i in range(0, (trials - 1)): # Establishes a for loop to iterate over the remaining trials (minus the first one)\n",
    "        \n",
    "        # Update the before parameter to be the created time (in utc) of the last item in the previous trail's dataframe\n",
    "        params_getter = {\n",
    "        'subreddit': subreddit,\n",
    "        'size': 1000,\n",
    "        'before': list(df['created_utc'][-1:])[0]\n",
    "        }\n",
    "        \n",
    "        # Get the data:\n",
    "        res_fnc = requests.get(url_fnc, params_getter)\n",
    "        print(res_fnc.status_code) # for debugging\n",
    "\n",
    "        # Make dataframe:\n",
    "        df = res_fnc.json() # Dump dat to a json\n",
    "        df = pd.DataFrame(df['data']) # Pull the 'data' dictionary out of the json\n",
    "\n",
    "        # Concatenate to master\n",
    "        master_df = pd.concat([master_df, df])\n",
    "        \n",
    "        # Add pull time to pull_times list:\n",
    "        pull_times.append(list(df['created_utc'][-1:])[0])\n",
    "        \n",
    "#=====  Create a text file with all the pull times for replicability =====================================================================\n",
    "    # Source inspring this code:  https://www.guru99.com/reading-and-writing-files-in-python.html\n",
    "    f = open(f'../data/{name}_pulltimes_{right_now}.txt',\"w+\")\n",
    "    f.write(f'{pull_times}')\n",
    "    f.close()\n",
    "\n",
    "#=====  Finally, return the fully concatenated master dataframe, reset index, store to csv  =================================================\n",
    "    master_df.reset_index(drop = True) # Source for refresher on how to tuse this:  https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html\n",
    "    master_df.to_csv(f'../data/{name}_{right_now}.csv')\n",
    "    return master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862bb6b3-802a-4711-a2e5-c88ba6250206",
   "metadata": {},
   "source": [
    "# Gather Data for TheOnion and WorldNews Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7757e614-fa54-430e-a2ef-c23d273efe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>gilded</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>hidden</th>\n",
       "      <th>pwls</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>...</th>\n",
       "      <th>is_gallery</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>gallery_data</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>call_to_action</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>removal_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td></td>\n",
       "      <td>t2_4a27h</td>\n",
       "      <td>0</td>\n",
       "      <td>Idiot Tornado Tears Harmlessly Through Empty F...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/TheOnion</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td></td>\n",
       "      <td>t2_3jamc</td>\n",
       "      <td>0</td>\n",
       "      <td>New Texas Law Requires Schools To Display Imag...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/TheOnion</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td></td>\n",
       "      <td>t2_3jamc</td>\n",
       "      <td>0</td>\n",
       "      <td>New Poll Finds Americans Would Respect Biden M...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/TheOnion</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td></td>\n",
       "      <td>t2_3jamc</td>\n",
       "      <td>0</td>\n",
       "      <td>Could You Pass Racial Discrimination Training ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/TheOnion</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheOnion</td>\n",
       "      <td></td>\n",
       "      <td>t2_3jamc</td>\n",
       "      <td>0</td>\n",
       "      <td>Dog And Owner Having Public Fight</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/TheOnion</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit selftext author_fullname  gilded  \\\n",
       "0  TheOnion                 t2_4a27h       0   \n",
       "1  TheOnion                 t2_3jamc       0   \n",
       "2  TheOnion                 t2_3jamc       0   \n",
       "3  TheOnion                 t2_3jamc       0   \n",
       "4  TheOnion                 t2_3jamc       0   \n",
       "\n",
       "                                               title link_flair_richtext  \\\n",
       "0  Idiot Tornado Tears Harmlessly Through Empty F...                  []   \n",
       "1  New Texas Law Requires Schools To Display Imag...                  []   \n",
       "2  New Poll Finds Americans Would Respect Biden M...                  []   \n",
       "3  Could You Pass Racial Discrimination Training ...                  []   \n",
       "4                  Dog And Owner Having Public Fight                  []   \n",
       "\n",
       "  subreddit_name_prefixed  hidden  pwls link_flair_css_class  ...  is_gallery  \\\n",
       "0              r/TheOnion   False     6                 None  ...         NaN   \n",
       "1              r/TheOnion   False     6                 None  ...         NaN   \n",
       "2              r/TheOnion   False     6                 None  ...         NaN   \n",
       "3              r/TheOnion   False     6                 None  ...         NaN   \n",
       "4              r/TheOnion   False     6                 None  ...         NaN   \n",
       "\n",
       "  media_metadata gallery_data  crosspost_parent_list crosspost_parent  \\\n",
       "0            NaN          NaN                    NaN              NaN   \n",
       "1            NaN          NaN                    NaN              NaN   \n",
       "2            NaN          NaN                    NaN              NaN   \n",
       "3            NaN          NaN                    NaN              NaN   \n",
       "4            NaN          NaN                    NaN              NaN   \n",
       "\n",
       "   author_created_utc retrieved_on call_to_action  author_cakeday  \\\n",
       "0                 NaN          NaN            NaN             NaN   \n",
       "1                 NaN          NaN            NaN             NaN   \n",
       "2                 NaN          NaN            NaN             NaN   \n",
       "3                 NaN          NaN            NaN             NaN   \n",
       "4                 NaN          NaN            NaN             NaN   \n",
       "\n",
       "  removal_reason  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_getter('theonion', 6, 'theonion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e0bbbd5-2d41-4587-9464-c623fc18f510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>gilded</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>hidden</th>\n",
       "      <th>pwls</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>...</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>retrieved_utc</th>\n",
       "      <th>updated_utc</th>\n",
       "      <th>utc_datetime_str</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldnews</td>\n",
       "      <td></td>\n",
       "      <td>t2_8q2g97db4</td>\n",
       "      <td>0</td>\n",
       "      <td>The parents of a 10-year-old boy living with a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/worldnews</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1682378382</td>\n",
       "      <td>1682378383</td>\n",
       "      <td>2023-04-24 23:19:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worldnews</td>\n",
       "      <td></td>\n",
       "      <td>t2_8q2g97db4</td>\n",
       "      <td>0</td>\n",
       "      <td>The parents of a 10-year-old boy living with a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/worldnews</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1682378313</td>\n",
       "      <td>1682378314</td>\n",
       "      <td>2023-04-24 23:18:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worldnews</td>\n",
       "      <td></td>\n",
       "      <td>t2_dss8b</td>\n",
       "      <td>0</td>\n",
       "      <td>Mexico finds tons of liquid meth in tequila bo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/worldnews</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1682377268</td>\n",
       "      <td>1682377268</td>\n",
       "      <td>2023-04-24 23:00:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worldnews</td>\n",
       "      <td></td>\n",
       "      <td>t2_9xhkarmen</td>\n",
       "      <td>0</td>\n",
       "      <td>Tucker Carlson Leaving Fox News, Last Episode ...</td>\n",
       "      <td>[{'e': 'text', 't': 'Not Appropriate Subreddit'}]</td>\n",
       "      <td>r/worldnews</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>normal</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1682377130</td>\n",
       "      <td>1682377131</td>\n",
       "      <td>2023-04-24 22:58:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worldnews</td>\n",
       "      <td></td>\n",
       "      <td>t2_2aex0igh</td>\n",
       "      <td>0</td>\n",
       "      <td>Film explores B.C. woman’s experience with mag...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/worldnews</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1682376678</td>\n",
       "      <td>1682376679</td>\n",
       "      <td>2023-04-24 22:51:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit selftext author_fullname  gilded  \\\n",
       "0  worldnews             t2_8q2g97db4       0   \n",
       "1  worldnews             t2_8q2g97db4       0   \n",
       "2  worldnews                 t2_dss8b       0   \n",
       "3  worldnews             t2_9xhkarmen       0   \n",
       "4  worldnews              t2_2aex0igh       0   \n",
       "\n",
       "                                               title  \\\n",
       "0  The parents of a 10-year-old boy living with a...   \n",
       "1  The parents of a 10-year-old boy living with a...   \n",
       "2  Mexico finds tons of liquid meth in tequila bo...   \n",
       "3  Tucker Carlson Leaving Fox News, Last Episode ...   \n",
       "4  Film explores B.C. woman’s experience with mag...   \n",
       "\n",
       "                                 link_flair_richtext subreddit_name_prefixed  \\\n",
       "0                                                 []             r/worldnews   \n",
       "1                                                 []             r/worldnews   \n",
       "2                                                 []             r/worldnews   \n",
       "3  [{'e': 'text', 't': 'Not Appropriate Subreddit'}]             r/worldnews   \n",
       "4                                                 []             r/worldnews   \n",
       "\n",
       "   hidden  pwls link_flair_css_class  ...  num_crossposts media  is_video  \\\n",
       "0   False     6                 None  ...               0  None     False   \n",
       "1   False     6                 None  ...               0  None     False   \n",
       "2   False     6                 None  ...               0  None     False   \n",
       "3   False     6               normal  ...               0  None     False   \n",
       "4   False     6                 None  ...               0  None     False   \n",
       "\n",
       "   retrieved_utc updated_utc     utc_datetime_str crosspost_parent_list  \\\n",
       "0     1682378382  1682378383  2023-04-24 23:19:26                   NaN   \n",
       "1     1682378313  1682378314  2023-04-24 23:18:19                   NaN   \n",
       "2     1682377268  1682377268  2023-04-24 23:00:56                   NaN   \n",
       "3     1682377130  1682377131  2023-04-24 22:58:38                   NaN   \n",
       "4     1682376678  1682376679  2023-04-24 22:51:04                   NaN   \n",
       "\n",
       "  crosspost_parent  author_cakeday link_flair_template_id  \n",
       "0              NaN             NaN                    NaN  \n",
       "1              NaN             NaN                    NaN  \n",
       "2              NaN             NaN                    NaN  \n",
       "3              NaN             NaN                    NaN  \n",
       "4              NaN             NaN                    NaN  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_getter('worldnews', 6, 'worldnews')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
